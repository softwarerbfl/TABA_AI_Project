{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPpAV9jOhFCQseLuTIKYBiG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softwarerbfl/TABA_AI_Project/blob/main/AlexNetModeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리"
      ],
      "metadata": {
        "id": "Kdg1NgF25XXD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "HUmsti8k5Uiu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import base64\n",
        "import zipfile\n",
        "import imageio\n",
        "import torch\n",
        "import h5py\n",
        "from google.colab import drive\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_2qqSzb5i8N",
        "outputId": "93c17f2f-5f35-4503-b88c-448f523dfa3c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#저작권 이미지 경로\n",
        "cpImage_path=\"/content/gdrive/My Drive/TABA_AI/Image/copyrighted/copyrightedImage_\"\n",
        "#비저작권 이미지 경로\n",
        "noncpImage_path=\"/content/gdrive/My Drive/TABA_AI/Image/noncopyrighted/ILSVRC2010_val_\""
      ],
      "metadata": {
        "id": "sVKb4Uea5yGr"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train 데이터셋 모으기**"
      ],
      "metadata": {
        "id": "IOB4NZGM5rBW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_cp_path=\"/content/gdrive/My Drive/TABA_AI/Image/train/cp/\"\n",
        "train_noncp_path=\"/content/gdrive/My Drive/TABA_AI/Image/train/noncp/\""
      ],
      "metadata": {
        "id": "-QPfqth060Cz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#저작권 이미지 90개 옮기기\n",
        "for i in range(90):\n",
        "  num='{0:08d}'.format(i)\n",
        "  img_path=cpImage_path+str(num)+\".JPEG\"\n",
        "  img=Image.open(img_path)\n",
        "  img.save(train_cp_path+\"copyrightedImage_\"+str(num)+'.JPEG')\n",
        "#비저작권 이미지 90개 옮기기\n",
        "for i in range(1,91):\n",
        "  num='{0:08d}'.format(i)\n",
        "  img_path=noncpImage_path+str(num)+'.JPEG'\n",
        "  img=Image.open(img_path)\n",
        "  img.save(train_noncp_path+\"noncopyrightedImage_\"+str(num)+\".JPEG\")"
      ],
      "metadata": {
        "id": "NxwYIVJV5neL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**test 데이터셋 모으기**"
      ],
      "metadata": {
        "id": "dFcLdT305thT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_cp_path=\"/content/gdrive/My Drive/TABA_AI/Image/test/cp/\"\n",
        "test_noncp_path=\"/content/gdrive/My Drive/TABA_AI/Image/test/noncp/\""
      ],
      "metadata": {
        "id": "UEd1ZKPW9jnt"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#저작권 이미지 10개 옮기기\n",
        "for i in range(90,100):\n",
        "  num='{0:08d}'.format(i)\n",
        "  img_path=cpImage_path+str(num)+\".JPEG\"\n",
        "  img=Image.open(img_path)\n",
        "  img.save(test_cp_path+\"copyrightedImage_\"+str(num)+'.JPEG')\n",
        "#비저작권 이미지 90개 옮기기\n",
        "for i in range(91,101):\n",
        "  num='{0:08d}'.format(i)\n",
        "  img_path=noncpImage_path+str(num)+'.JPEG'\n",
        "  img=Image.open(img_path)\n",
        "  img.save(test_noncp_path+\"noncopyrightedImage_\"+str(num)+\".JPEG\")"
      ],
      "metadata": {
        "id": "AnZS5R1H9tAV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DataLoader로 이미지 데이터 가져오기**"
      ],
      "metadata": {
        "id": "DaNmeBDe_NLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ImageTransform():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.data_transform = transforms.Compose([\n",
        "            transforms.RandomCrop(256),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "    def __call__(self, img):\n",
        "        return self.data_transform(img)"
      ],
      "metadata": {
        "id": "jkm9MsT4SYcg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                                       #transforms.Resize(224),\n",
        "                                       transforms.CenterCrop(256),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                                      #transforms.Resize(224),\n",
        "                                      transforms.CenterCrop(256),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "# train_data = datasets.ImageFolder(DATASET_PATH + '/train', transform=train_transforms)\n",
        "# test_data = datasets.ImageFolder(DATASET_PATH + '/test', transform=test_transforms)\n",
        "\n",
        "# train_iter=torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
        "# test_iter=torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)\n",
        "\n",
        "print(\"Preparing dataset done\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pjr-Xj6qgf8x",
        "outputId": "a91f99f0-f5d0-4abd-b945-2b6a39b7da70"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing dataset done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "train_dataset=ImageFolder(\"/content/gdrive/My Drive/TABA_AI/Image/train\",transform=train_transforms)\n",
        "test_dataset=ImageFolder(\"/content/gdrive/My Drive/TABA_AI/Image/test\",transform=test_transforms)"
      ],
      "metadata": {
        "id": "IKIqVRgp_RRR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_iter=DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=1)\n",
        "test_iter=DataLoader(test_dataset, batch_size=32, shuffle=True, num_workers=1)"
      ],
      "metadata": {
        "id": "PlZvasAD_ROY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AlexNet"
      ],
      "metadata": {
        "id": "05-LBpCV-aku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델 선언**"
      ],
      "metadata": {
        "id": "PWpv0btH-gUb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.CNN=nn.Sequential(\n",
        "        # MaxPooling층: 데이터의 중요한 요소들만 요약하여 추출\n",
        "        nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.LocalResponseNorm(size=5, k=2),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "        # MaxPooling층: 데이터의 중요한 요소들만 요약하여 추출\n",
        "        nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.LocalResponseNorm(size=5, k=2),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "        # 중간다리 역할 \n",
        "        nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.LocalResponseNorm(size=5, k=2),\n",
        "\n",
        "        # 중간다리 역할 \n",
        "        nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.LocalResponseNorm(size=5, k=2),\n",
        "\n",
        "        # 중간다리 역할 \n",
        "        nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.LocalResponseNorm(size=5, k=2),\n",
        "\n",
        "        # MaxPooling층 : Fully Connected 층 2개로 구성 \n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    )\n",
        "    self.FC = nn.Sequential(\n",
        "        nn.Linear(256*6*6, 4096),\n",
        "        nn.ReLU(True),\n",
        "        nn.Dropout(0.5),\n",
        "\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.ReLU(True),\n",
        "        nn.Dropout(0.5),\n",
        "\n",
        "        nn.Linear(4096, 2),\n",
        "        nn.Softmax()\n",
        "    )\n",
        "  def forward(self, inp):\n",
        "    cnn_res = self.CNN(inp)\n",
        "    flatten = torch.flatten(cnn_res, 1)\n",
        "    fc_res = self.FC(flatten)\n",
        "    return fc_res"
      ],
      "metadata": {
        "id": "euNQt7EK-iOa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlexNet()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDsD6PJD_Cz1",
        "outputId": "a7ade12b-8307-4d1b-938a-b796e57efe64"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (CNN): Sequential(\n",
              "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
              "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
              "    (11): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
              "    (14): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
              "    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (FC): Sequential(\n",
              "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
              "    (7): Softmax(dim=None)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**train(훈련) 함수 선언**"
      ],
      "metadata": {
        "id": "KAafkfro-9yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_eval(model, data_iter, batch_size):\n",
        "  with torch.no_grad():\n",
        "    test_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    model.eval()\n",
        "    for batch_img, batch_lab in data_iter:\n",
        "      X = batch_img.to(device)\n",
        "      Y = batch_lab.to(device)\n",
        "      y_pred = model(X)\n",
        "      _, predicted = torch.max(y_pred.data, 1)\n",
        "      correct += (predicted == Y).sum().item()\n",
        "      total += batch_img.size(0)\n",
        "    \n",
        "    # plt.figure(figsize=(5,6))\n",
        "    # for i in range(20):\n",
        "    #   plt.subplot(4,5,i+1)\n",
        "    #   plt.imshow(X[i])\n",
        "    #   plt.title(\"real:\",Y[i],\"predict:\",predicted[i])\n",
        "    #   plt.axis('off')\n",
        "    # plt.show()\n",
        "    val_acc = (100*correct / total)\n",
        "    model.train()\n",
        "  print(\"real:\",Y)\n",
        "  print(\"predict:\",predicted)\n",
        "  return val_acc"
      ],
      "metadata": {
        "id": "7cOYsrHf-8k7"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import optim\n",
        "optimizer=optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion=nn.CrossEntropyLoss() #\n",
        "EPOCHS=30\n",
        "## Training Phase\n",
        "print_every = 1\n",
        "print(\"Start training !\")\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(30):\n",
        "  loss_val_sum = 0\n",
        "  for batch_img, batch_lab in train_iter:\n",
        "\n",
        "    X = batch_img.to(device)\n",
        "    Y = batch_lab.to(device)\n",
        "\n",
        "    # inference & Calculate loss\n",
        "    y_pred = model.forward(X)\n",
        "    loss = criterion(y_pred, Y)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_val_sum += loss\n",
        "\n",
        "  if ((epoch%print_every)==0) or (epoch==(EPOCHS-1)):\n",
        "    #accr_val = M.test(x_test, y_test, batch_size)\n",
        "    loss_val_avg = loss_val_sum / len(train_iter)\n",
        "    accr_val = test_eval(model, train_iter, 32)\n",
        "    print(f\"epoch:[{epoch+1}/{30}] cost:[{loss_val_avg: .3f}] test_accuracy:[{accr_val:.3f}]\")\n",
        "\n",
        "print(\"Training Done! \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8etXIxTJ_Hzi",
        "outputId": "81ec9465-6980-4eed-a82e-cfea75c84d12"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training !\n",
            "epoch:[1/30] cost:[ 0.577] test_accuracy:[65.979]\n",
            "epoch:[2/30] cost:[ 0.701] test_accuracy:[73.711]\n",
            "epoch:[3/30] cost:[ 0.555] test_accuracy:[72.680]\n",
            "epoch:[4/30] cost:[ 0.549] test_accuracy:[72.680]\n",
            "epoch:[5/30] cost:[ 0.569] test_accuracy:[75.258]\n",
            "epoch:[6/30] cost:[ 0.582] test_accuracy:[75.258]\n",
            "epoch:[7/30] cost:[ 0.562] test_accuracy:[77.320]\n",
            "epoch:[8/30] cost:[ 0.532] test_accuracy:[74.742]\n",
            "epoch:[9/30] cost:[ 0.528] test_accuracy:[75.773]\n",
            "epoch:[10/30] cost:[ 0.596] test_accuracy:[77.320]\n",
            "epoch:[11/30] cost:[ 0.549] test_accuracy:[71.134]\n",
            "epoch:[12/30] cost:[ 0.584] test_accuracy:[71.134]\n",
            "epoch:[13/30] cost:[ 0.616] test_accuracy:[71.649]\n",
            "epoch:[14/30] cost:[ 0.607] test_accuracy:[68.557]\n",
            "epoch:[15/30] cost:[ 0.644] test_accuracy:[76.289]\n",
            "epoch:[16/30] cost:[ 0.589] test_accuracy:[76.289]\n",
            "epoch:[17/30] cost:[ 0.574] test_accuracy:[74.227]\n",
            "epoch:[18/30] cost:[ 0.526] test_accuracy:[76.804]\n",
            "epoch:[19/30] cost:[ 0.511] test_accuracy:[78.351]\n",
            "epoch:[20/30] cost:[ 0.506] test_accuracy:[78.351]\n",
            "epoch:[21/30] cost:[ 0.563] test_accuracy:[77.835]\n",
            "epoch:[22/30] cost:[ 0.592] test_accuracy:[77.320]\n",
            "epoch:[23/30] cost:[ 0.526] test_accuracy:[75.773]\n",
            "epoch:[24/30] cost:[ 0.530] test_accuracy:[75.258]\n",
            "epoch:[25/30] cost:[ 0.587] test_accuracy:[78.351]\n",
            "epoch:[26/30] cost:[ 0.498] test_accuracy:[79.381]\n",
            "epoch:[27/30] cost:[ 0.509] test_accuracy:[78.351]\n",
            "epoch:[28/30] cost:[ 0.582] test_accuracy:[67.526]\n",
            "epoch:[29/30] cost:[ 0.527] test_accuracy:[72.165]\n",
            "epoch:[30/30] cost:[ 0.612] test_accuracy:[77.320]\n",
            "Training Done! \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**테스트**"
      ],
      "metadata": {
        "id": "czQ5jmSZjFCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "accr_val = test_eval(model, test_iter, 32)\n",
        "print(f\"test_accuracy:[{accr_val:.3f}]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djSBUVhSihW6",
        "outputId": "ecb8a26d-b65e-46c2-9334-99722376bd48"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "real: tensor([0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0],\n",
            "       device='cuda:0')\n",
            "predict: tensor([1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
            "       device='cuda:0')\n",
            "test_accuracy:[70.000]\n"
          ]
        }
      ]
    }
  ]
}