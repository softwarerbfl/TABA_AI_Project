{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softwarerbfl/TABA_AI_Project/blob/main/AlexNetModeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdg1NgF25XXD"
      },
      "source": [
        "# 전처리"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HUmsti8k5Uiu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import base64\n",
        "import zipfile\n",
        "import imageio\n",
        "import torch\n",
        "import h5py\n",
        "from google.colab import drive\n",
        "import torchvision\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "M_2qqSzb5i8N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a02987b-ae10-4d36-97ce-7bf861f27382"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "sVKb4Uea5yGr"
      },
      "outputs": [],
      "source": [
        "#저작권 이미지 경로\n",
        "cpImage_path=\"/content/drive/MyDrive/TABA_AI/Image/copyrighted/copyrightedImage\"\n",
        "#비저작권 이미지 경로\n",
        "noncpImage_path=\"/content/gdrive/My Drive/TABA_AI/Image/noncopyrighted/ILSVRC2010_val_\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4bdoBcwKF1t"
      },
      "source": [
        "**평가지표 측정 함수**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "YZ2Nb1oSKIEb"
      },
      "outputs": [],
      "source": [
        "def evaluation_index(predict, real):\n",
        "  TP=0.0\n",
        "  TN=0.0\n",
        "  FP=0.0\n",
        "  FN=0.0\n",
        "  for i in range(len(predict)):\n",
        "    for j in range(len(predict[i])):\n",
        "      if predict[i][j]==real[i][j]:\n",
        "       if predict[i][j]==1:\n",
        "         TN+=1\n",
        "       else:\n",
        "         TP+=1\n",
        "      else:\n",
        "       if predict[i][j]==0:\n",
        "        FP+=1\n",
        "       else:\n",
        "        FN+=1\n",
        "\n",
        "    \n",
        "  accuracy=(TP+TN)/(TP+TN+FP+FN)\n",
        "  recall=TP/(TP+FN)\n",
        "  precision=TP/(TP+FP)\n",
        "  F1=(2*precision*recall)/(precision+recall)\n",
        "  print(\"accuracy:\",accuracy)\n",
        "  print(\"recall:\",recall)\n",
        "  print(\"precision:\",precision)\n",
        "  print(\"F1:\",F1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaNmeBDe_NLs"
      },
      "source": [
        "**DataLoader로 이미지 데이터 가져오기**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "y32FA_fU2fCh"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE=16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "Pjr-Xj6qgf8x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4b9dd83-fb0f-4e65-b388-a960be26d250"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preparing dataset done\n"
          ]
        }
      ],
      "source": [
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "train_transforms = transforms.Compose([\n",
        "                                       transforms.CenterCrop(256),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                            [0.229, 0.224, 0.225])])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "                                      transforms.CenterCrop(256),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                                                           [0.229, 0.224, 0.225])])\n",
        "\n",
        "# train_data = datasets.ImageFolder(DATASET_PATH + '/train', transform=train_transforms)\n",
        "# test_data = datasets.ImageFolder(DATASET_PATH + '/test', transform=test_transforms)\n",
        "\n",
        "# train_iter=torch.utils.data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
        "# test_iter=torch.utils.data.DataLoader(test_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)\n",
        "\n",
        "print(\"Preparing dataset done\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "IKIqVRgp_RRR"
      },
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "train_dataset=ImageFolder(\"/content/drive/MyDrive/TABA_AI/Image/Folder/train\",transform=train_transforms)\n",
        "test_dataset=ImageFolder(\"/content/drive/MyDrive/TABA_AI/Image/Folder/test\",transform=test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "PlZvasAD_ROY"
      },
      "outputs": [],
      "source": [
        "train_iter=DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)\n",
        "test_iter=DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05-LBpCV-aku"
      },
      "source": [
        "# AlexNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWpv0btH-gUb"
      },
      "source": [
        "**모델 선언**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "euNQt7EK-iOa"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.CNN=nn.Sequential(\n",
        "        # MaxPooling층: 데이터의 중요한 요소들만 요약하여 추출\n",
        "        nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.LocalResponseNorm(size=5, k=2),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "        # MaxPooling층: 데이터의 중요한 요소들만 요약하여 추출\n",
        "        nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.LocalResponseNorm(size=5, k=2),\n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "        # 중간다리 역할 \n",
        "        nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.LocalResponseNorm(size=5, k=2),\n",
        "\n",
        "        # 중간다리 역할 \n",
        "        nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.LocalResponseNorm(size=5, k=2),\n",
        "\n",
        "        # 중간다리 역할 \n",
        "        nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(inplace = True),\n",
        "        nn.LocalResponseNorm(size=5, k=2),\n",
        "\n",
        "        # MaxPooling층 : Fully Connected 층 2개로 구성 \n",
        "        nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "    )\n",
        "    self.FC = nn.Sequential(\n",
        "        nn.Linear(256*6*6, 4096),\n",
        "        nn.ReLU(True),\n",
        "        nn.Dropout(0.5),\n",
        "\n",
        "        nn.Linear(4096, 4096),\n",
        "        nn.ReLU(True),\n",
        "        nn.Dropout(0.5),\n",
        "\n",
        "        nn.Linear(4096, 2)\n",
        "    )\n",
        "  def forward(self, inp):\n",
        "    cnn_res = self.CNN(inp)\n",
        "    flatten = torch.flatten(cnn_res, 1)\n",
        "    fc_res = self.FC(flatten)\n",
        "    return fc_res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "PDsD6PJD_Cz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d5fc1c6-34dd-4375-f0f2-a728df29b734"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AlexNet(\n",
              "  (CNN): Sequential(\n",
              "    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
              "    (3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
              "    (7): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
              "    (11): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
              "    (14): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): LocalResponseNorm(5, alpha=0.0001, beta=0.75, k=2)\n",
              "    (17): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (FC): Sequential(\n",
              "    (0): Linear(in_features=9216, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ],
      "source": [
        "model = AlexNet()\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAafkfro-9yK"
      },
      "source": [
        "**train(훈련) 함수 선언**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "7cOYsrHf-8k7"
      },
      "outputs": [],
      "source": [
        "def test_eval(model, data_iter, batch_size):\n",
        "  return_y=[]\n",
        "  return_predict=[]\n",
        "  with torch.no_grad():\n",
        "    test_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    model.eval()\n",
        "    for batch_img, batch_lab in data_iter:\n",
        "      X = batch_img.to(device)\n",
        "      Y = batch_lab.to(device)\n",
        "      y_pred = model(X)\n",
        "      _, predicted = torch.max(y_pred.data, 1)\n",
        "      correct += (predicted == Y).sum().item()\n",
        "      total += batch_img.size(0)\n",
        "      return_y.append(Y.tolist())\n",
        "      return_predict.append(predicted.tolist())\n",
        "\n",
        "    \n",
        "    val_acc = (100*correct / total)\n",
        "    model.train()\n",
        "  # print(\"real:\",Y)\n",
        "  # print(\"predict:\",predicted)\n",
        "  return val_acc,return_y,return_predict #정확도, 실제값, 예측값 반환"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "8etXIxTJ_Hzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94370f60-37c2-47d8-fa59-a9b5a270dac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch Size: 16 ,Learning Rate: 0.0001\n",
            "Start training !\n",
            "epoch: 1 / 30  costs: 0.6313969492912292  test_accuracy: 69.8125\n",
            "epoch: 2 / 30  costs: 0.5808980464935303  test_accuracy: 72.825\n",
            "epoch: 3 / 30  costs: 0.5561648011207581  test_accuracy: 71.575\n",
            "epoch: 4 / 30  costs: 0.533268392086029  test_accuracy: 74.4125\n",
            "epoch: 5 / 30  costs: 0.5147956609725952  test_accuracy: 72.4625\n",
            "epoch: 6 / 30  costs: 0.4860383868217468  test_accuracy: 75.225\n",
            "epoch: 7 / 30  costs: 0.4638483226299286  test_accuracy: 80.275\n",
            "epoch: 8 / 30  costs: 0.431165486574173  test_accuracy: 83.3875\n",
            "epoch: 9 / 30  costs: 0.4042447507381439  test_accuracy: 85.5375\n",
            "epoch: 10 / 30  costs: 0.36717864871025085  test_accuracy: 86.6125\n",
            "epoch: 11 / 30  costs: 0.31184905767440796  test_accuracy: 90.1125\n",
            "epoch: 12 / 30  costs: 0.2591738700866699  test_accuracy: 93.125\n",
            "epoch: 13 / 30  costs: 0.2010347545146942  test_accuracy: 92.7125\n",
            "epoch: 14 / 30  costs: 0.15873700380325317  test_accuracy: 96.15\n",
            "epoch: 15 / 30  costs: 0.11901718378067017  test_accuracy: 97.9625\n",
            "epoch: 16 / 30  costs: 0.09926103055477142  test_accuracy: 98.2625\n",
            "epoch: 17 / 30  costs: 0.08084736764431  test_accuracy: 98.8625\n",
            "epoch: 18 / 30  costs: 0.07922470569610596  test_accuracy: 97.8\n",
            "epoch: 19 / 30  costs: 0.059728797525167465  test_accuracy: 99.2625\n",
            "epoch: 20 / 30  costs: 0.06108426675200462  test_accuracy: 99.5125\n",
            "epoch: 21 / 30  costs: 0.052259210497140884  test_accuracy: 98.9875\n",
            "epoch: 22 / 30  costs: 0.04906405135989189  test_accuracy: 98.2625\n",
            "epoch: 23 / 30  costs: 0.05290523171424866  test_accuracy: 98.9125\n",
            "epoch: 24 / 30  costs: 0.049140382558107376  test_accuracy: 99.1\n",
            "epoch: 25 / 30  costs: 0.04406728595495224  test_accuracy: 99.1875\n",
            "epoch: 26 / 30  costs: 0.03675274923443794  test_accuracy: 98.7875\n",
            "epoch: 27 / 30  costs: 0.03847383335232735  test_accuracy: 99.0625\n",
            "epoch: 28 / 30  costs: 0.05005144327878952  test_accuracy: 99.0125\n",
            "epoch: 29 / 30  costs: 0.039554446935653687  test_accuracy: 99.0375\n",
            "epoch: 30 / 30  costs: 0.03914107382297516  test_accuracy: 99.1125\n",
            "Training Done! \n",
            "average accuracy: 90.845\n"
          ]
        }
      ],
      "source": [
        "from torch import optim\n",
        "lr=0.0001\n",
        "optimizer=optim.NAdam(model.parameters(), lr=lr)\n",
        "criterion=nn.CrossEntropyLoss() #손실함수\n",
        "EPOCHS=30\n",
        "avg_acc=[]\n",
        "print(\"Batch Size:\",BATCH_SIZE, \",Learning Rate:\",lr)\n",
        "## Training Phase\n",
        "print_every = 1\n",
        "print(\"Start training !\")\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "  loss_val_sum = 0\n",
        "  for batch_img, batch_lab in train_iter:\n",
        "\n",
        "    X = batch_img.to(device)\n",
        "    Y = batch_lab.to(device)\n",
        "\n",
        "    # inference & Calculate loss\n",
        "    y_pred = model.forward(X)\n",
        "    loss = criterion(y_pred, Y)\n",
        "\n",
        "    # print(y_pred)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_val_sum += loss\n",
        "\n",
        "  if ((epoch%print_every)==0) or (epoch==(EPOCHS-1)):\n",
        "    #accr_val = M.test(x_test, y_test, batch_size)\n",
        "    loss_val_avg = loss_val_sum / len(train_iter)\n",
        "    accr_val,_,_ = test_eval(model, train_iter, BATCH_SIZE)\n",
        "    print(\"epoch:\",epoch+1,\"/\",EPOCHS,\" costs:\",loss_val_avg.item(), \" test_accuracy:\",accr_val)\n",
        "    avg_acc.append(accr_val)\n",
        "print(\"Training Done! \")\n",
        "print(\"average accuracy:\",sum(avg_acc)/len(avg_acc))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czQ5jmSZjFCB"
      },
      "source": [
        "**테스트**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "djSBUVhSihW6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ba6b11-bea0-49aa-dd83-5171b03b833d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 0.7385\n",
            "recall: 0.774\n",
            "precision: 0.7226890756302521\n",
            "F1: 0.7474649927571222\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "accr_val,Y,predicted = test_eval(model, test_iter, BATCH_SIZE)\n",
        "evaluation_index(predicted,Y)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}